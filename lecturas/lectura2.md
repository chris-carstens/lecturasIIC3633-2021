 # Matrix factorization techniques for recommender systems

Este paper introduce la temática de sistemas recomendadores, definiendo, contrastando y ejemplificando dos *aproachs: content filtering and colaborative filtering*. En particular, y en base a esto, muestra la alternativa de los *latent factor models*, los cuales son un tercer *approach* que intenta explicar los ratings, utilizando una mezcla de los dos anterios, es decir, caracterizando ítems y usuarios.
En particular, en este último enfoque mencionado, el paper se enfoca en el modelo basado en *matrix factorization*, el cual mapea usuarios e ítems a un *joint latent factor space* de una determinada dimensión, de modo que las interacciones usuario-ítem son modeladas como productosd internos en ese espacio.

Personalmente considero que el texto logra introducir con ejemplos prácticos las técnicas de factorización matricial. Primero, nos hace un nexo con los métodos base, *content and colaborative filtering*, contrastándolos con esta nueva alternativa. Así, mantiene el hilo conductor respecto a lo ya conocido, y utiliza gráficas explícitas y explicadas para entender el nuevo enfoque del modelo explicado. Se hace bastante agradable en que no necesariamente se enfoque desde una perspectiva técnica o asuma conceptos obvios, sino que haya una explicación progesiva y a través de modelos simplificados que permiten entender más fácilemente de manera inicial.

Si bien en los puntos generales la lectura fue muy explícita y fácil, en los apartados más específicos, ya sea respecto a los defectos o características del modelo, queda en algunos puntos al debe. Por ejemplo, dentro de los *learning algorithms*, se da una pincelada muy general en cuanto al *Stochastic gradient descent*. Particularmente, me había tocado conocer este algoritmo con anterioridad, por lo que consideré la explicación muy fugaz. Se muestras las ecuaciones o parte del seudo algoritmo de manera directa, pero no se habla más respecto a cómo se escogen los parámetros de aprendizaje, de qué manera o tendencia tiene el algoritmo para converger dentro de ciertos rangos, o simplemente, no se explicita el algoritmo para entenderlo en esta lectura. 


También, en el apartado que realizaron respecto al Netflix Prize, mencionan que realizaron variaciones al método que presentan en el paper, para participar de este concurso con el cual lograron mejorar los resultados, pero no se explicitan cuáles. Quizás la razón es obvia y básicamente no podían dar a la luz esto, pero deja la duda en quienes somos curiosos.
Por otro lado, también se concluye que el algoritmo es eficiente en cuanto a memoria, pero en ningún caso se explica el porqué, ni tampoco se entregan ejemplos empíricos de las dimensiones de esta eficiencia. Por lo mismo, me queda la duda de cómo se logró esta, o qué parte del algoritmo permite este ahorro de memoria. En caso de querer realizar una modificación en el algoritmo, mantendría esta incógnita, o probablemente el paper asume un conocimiento previo para darlo por entendido. Dicho este punto, y considerando que cuando se trata de bases de datos con niveles exponenciales en su crecimiento, es funtamental conocer las limitaciones de memoria de los algoritmos. Takács, Pilászy, Németh & Tikk (2008) nos entregan nociones respecto a las dimensiones en memoria de algunos modelos de factorización matricial para sistemas recomendadores. Por ejemplo, nos muestran que estos algoritmos basados en vecinos son *memory-based*, donde almacenan toda la información en memoria, la cual es usada para computar los distintos algoritmos. Por lo mismo, ellos proponen una corrección o alternativa de estos métodos clásicos de factorización matricial basada en vecinos, de tal manera de mejorar la eficiencia en memoria. Dados determinados sets de datos de I usuarios, J ítems, R posibles ratings, y utilizando una factorización arbitraria X = UM, donde U es una matriz de I x K y M una matriz de K x J, los autores llegaron a un algoritmo capaz de resolver el problema en un orden de memoria de O(IK + KJ), mejorándolo respecto al método de referencia que utilizaron (basado en vecinos), con orden de O(J^2+|R|). De esta manera, podemos tener en mente los órdenes de infraestructura, hardware o memoria que necesitaremos para computar determinados métodos.


**Referencia base:** 
- Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30-37.

**Referencias complementarias**

- Takács, G., Pilászy, I., Németh, B., & Tikk, D. (2008). Investigation of Various Matrix Factorization Methods for Large Recommender Systems. 2008 IEEE International Conference on Data Mining Workshops. doi:10.1109/icdmw.2008.86 


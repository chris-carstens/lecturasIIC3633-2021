# Evaluating Recommendation Systems

El paper entrega una noción global, inicalmente con un enfoque mnás cualitatitvo que cuantitavivo, de los métodos o experimentos para evaluar los sistemas recomendadores, ya sea con usuarios directamente u offline, mediante datasets *prearmados*. Posteriormenrte, muestra indicadores estadísticos de confianza para cada experimento presentado en el punto anterior, resume las distintas propiedades que puede tener un sistema recomendador, cómo imopactan la performance del mismo, como también plantea métricas para medir estas distintas propiedades.

Un punto que recalcco en este paper, es que particularmente el capítulo 2, *Experimental Settings*, se tiene un enfoquer muy cualitativo. Más como opinión personal, me faltaron demostraciones empíricas de los métodos, o ejemplos de lugares en los que se aplicó cada uno, ya sean experimentos offline o con usuarios de por medio. En grandes partes, sentí que abarcó puntos muy generales en este episodio, que muchas veces no era necesario alargar la explicación sin demostración o tangibilizar. Sin embargo, el paper luego muestra una variedad de tests o métodos para asegurar la confianza de lo presentado anteriormente, por lo que en parte, entrega un respaldo teórico a los distintos experimentos. Además, ya dentro de las métricas de los sistemas recomendadores, se vuelven a retomar parte de estos puntos, entregando medidas de desempeño según la utilidad desdeada.

Considero que se podria haber aprovechado de ejemplificar (o a lo menos mencionar referencias), de los problemas que producían los distintos métodos. Por ejemplo, en el caso de *user studies*, se mencionaron desventajas como el hecho de que participantes del estudio sean voluntarios, lo que claramente cesgará la muestra a personas interesadas en la temática. También, la presencia del cesgo por estar consciente de que se está participando de un experimento, y no en una situación real, o finalmente el hecho de que recibir un pago produce la tendencia a intentar satisfacer a la persona que condeue el experimento. El único atisbo de solución que se entrega es “no revelar el objetivo del experimento”. Sin embargo, este en ningún caso es una solución para los tan relevantes cesgos que se producen en los datos o experimentos, y me genera desconfianza acerca de la validez de los datos que se pueden obtener con los mismos. Hubiese esperado que los autores, al presentar un problema, entreguen posibles métodos para disminuir estos cesgos, o referenciar investigación bibliográfica que investigue este hecho y su influencia real en los resultados de un sistema recomendador.

En este sentido, uno de los grandes sesgos prsentes en los sistemas recomendadores, es a entregar resultados sesgados a las soluciones entregadas por métodos no personalizados, por ejemplo *most popular*. Cremonesi, Koren y Turrin, nos recomiendan múltiples veces en su análisis particular de los algoritmos de *top-n recommendations*, la necesidad de constuir un set de datos que no tenga un sesgo a entregar resultados no personalizados, tenfiendo a maximizar las métricas asociadas a estos. Por ejemplo, muestran que en el modelo basado en vecinos, existen sesgos que representan el hecho de que ciertos ítems tienden a recibir calificaciones más altas que otros ítems probablemente "menos populares". También incluyen los efectos de uso que representan la tendencia de ciertos usuarios a calificar más altos que otros (2010). Basta con pensar que esto también se ve reflejado en los experimentos con usuarios, donde cesgar una muestra a usuarios que tienen mayor agrado a la temática, tenderá a producir efectos más positivos, entre otros diversos factores que pueden existir en esta interacción.
Estos son claros ejemplos de la necesidad de saber minimizar los factores que desvían la muestra respecto a la población real, ya sea en usuarios propiamente tal, o enm sets de datos, donde obtener fuentes correctas de datos, como también procesarlos de manera de entregar un input sin cesgo a los sistemas recomendadores, es clave. Con esto, gracias a las múltiples métricas entregadas en el paper de lectura actual, es posible disminuir ciertos cesgos de manera de priorizar determinadas métricas según el objetivo del sistema recomendador. Sin embargo, y como recalca el texto, siempre es fundamental hacerlo manteniendo dentro de ciertos rangos la confianza del resto de las métricas, de manera de evitar el problema de que al corregir uno, aparezcan dos más.

**Referencia base:** 
- Guy, S., & Gunawardana, A.. (2011) “Evaluating recommendation systems.” In Recommender systems handbook, pp. 257-297. Springer US, 2011.

**Referencias complementarias**
- Cremonesi, P., Koren, Y., & Turrin, R. (2010). Performance of recommender algorithms on top-n recommendation tasks. Proceedings of the Fourth ACM Conference on Recommender Systems - RecSys  ’10. doi:10.1145/1864708.1864721
